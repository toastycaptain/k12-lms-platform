{
  "project": "k12-lms-platform",
  "branchName": "ralph/m6-ai-gateway",
  "description": "M6: AI Gateway — Admin model registry, task policies, AI-assisted planning, and auditing per PRD-14, PRD-21, PRD-22, and PRD-25",
  "userStories": [
    {
      "id": "US-082",
      "title": "Initialize FastAPI ai-gateway service with health endpoint",
      "description": "As a developer, I need the FastAPI ai-gateway service scaffolded with project structure, configuration, health check, and tests so it can serve as the AI model adapter layer.",
      "acceptanceCriteria": [
        "Create apps/ai-gateway/ with standard FastAPI project structure: main.py, requirements.txt, Dockerfile, .env.example, tests/",
        "requirements.txt includes: fastapi>=0.115, uvicorn[standard], pydantic>=2.0, httpx, python-dotenv, pytest, pytest-asyncio, pytest-httpx",
        "main.py: FastAPI app with title='K-12 LMS AI Gateway', version='1.0.0'",
        "GET /v1/health endpoint returns { status: 'ok', version: '1.0.0', timestamp: ISO8601 }",
        "App configuration via environment variables: AI_GATEWAY_PORT (default 8000), AI_GATEWAY_ENV (default 'development'), CORS_ORIGINS (default 'http://localhost:3000')",
        "CORS middleware configured with CORS_ORIGINS env var",
        "Request logging middleware that logs method, path, status_code, duration_ms",
        "Error handling middleware that catches exceptions and returns { error: message, status_code: int } JSON responses",
        "app/config.py: Settings class using pydantic BaseSettings for typed env var loading",
        "app/routers/ directory for route organization (v1 router prefix)",
        "Dockerfile: python:3.12-slim, install requirements, expose port, run uvicorn",
        "tests/test_health.py: test health endpoint returns 200 with correct shape",
        "pytest passes with 0 failures",
        "App starts successfully with: cd apps/ai-gateway && pip install -r requirements.txt && uvicorn app.main:app"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Tech Spec 2.1, 2.2: ai-gateway is the isolated FastAPI service for AI model adapters, prompts, and safety. This story establishes the project foundation. The service communicates with Rails Core via HTTP."
    },
    {
      "id": "US-083",
      "title": "AI provider adapter layer with model registry",
      "description": "As a developer, I need a provider adapter abstraction so the gateway can route AI requests to different LLM providers (OpenAI, Anthropic) based on configuration.",
      "acceptanceCriteria": [
        "app/providers/base.py: abstract BaseProvider class with async methods — generate(prompt, model, temperature, max_tokens, system_prompt) returns GenerateResponse; stream(prompt, model, temperature, max_tokens, system_prompt) yields StreamChunk",
        "GenerateResponse pydantic model: content (str), model (str), provider (str), usage { prompt_tokens: int, completion_tokens: int, total_tokens: int }, finish_reason (str)",
        "StreamChunk pydantic model: content (str), done (bool), usage (optional, present on last chunk)",
        "app/providers/openai_provider.py: OpenAIProvider extends BaseProvider; uses httpx async client to call OpenAI Chat Completions API; requires OPENAI_API_KEY env var; supports models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo",
        "app/providers/anthropic_provider.py: AnthropicProvider extends BaseProvider; uses httpx async client to call Anthropic Messages API; requires ANTHROPIC_API_KEY env var; supports models: claude-sonnet-4-5-20250929, claude-haiku-4-5-20251001",
        "app/providers/registry.py: ProviderRegistry class — register_provider(name, provider_class), get_provider(name) returns provider instance, list_providers() returns registered provider names",
        "Default registry pre-registers 'openai' and 'anthropic' providers",
        "GET /v1/providers endpoint returns list of registered providers with their supported models: [{ name: 'openai', models: [...] }, { name: 'anthropic', models: [...] }]",
        "Provider errors (auth failures, rate limits, timeouts) wrapped in ProviderError with status_code, provider, and message",
        "httpx timeout: 120 seconds for generate, 180 seconds for stream",
        "tests/test_providers.py: test provider registration, test generate with mocked HTTP responses (httpx mock), test error wrapping",
        "tests/test_provider_endpoint.py: test GET /v1/providers returns correct shape",
        "pytest passes with 0 failures"
      ],
      "priority": 2,
      "passes": true,
      "notes": "Tech Spec 2.1, 2.10: The provider adapter pattern allows adding new LLM providers without changing the core gateway logic. Registry pattern enables runtime discovery. Real API calls are never made in tests — all HTTP is mocked."
    },
    {
      "id": "US-084",
      "title": "AI generate endpoint with prompt processing and safety filters",
      "description": "As a developer, I need the gateway's /v1/generate endpoint to accept prompts, apply safety filters, route to the configured provider, and return structured responses.",
      "acceptanceCriteria": [
        "POST /v1/generate endpoint accepts JSON body: { provider: str, model: str, prompt: str, system_prompt: str (optional), temperature: float (default 0.7), max_tokens: int (default 2048), task_type: str (optional, e.g. 'lesson_generation', 'differentiation', 'assessment', 'rewrite'), context: dict (optional, metadata passed through) }",
        "Request validation: provider must be registered, model must be supported by provider, prompt must be non-empty and <= 32000 chars, temperature 0.0-2.0, max_tokens 1-16384",
        "app/safety/filters.py: SafetyFilter class with check_input(prompt, task_type) and check_output(content, task_type) methods; input filter rejects prompts containing obvious injection patterns (e.g. 'ignore previous instructions'); output filter is a no-op placeholder for now (returns content unchanged)",
        "Safety filter is applied before sending to provider and after receiving response",
        "Response shape: { id: uuid, content: str, model: str, provider: str, usage: { prompt_tokens, completion_tokens, total_tokens }, finish_reason: str, task_type: str, created_at: ISO8601 }",
        "Request includes X-Tenant-ID and X-User-ID headers (passed through from Rails, not validated by gateway — Rails handles auth)",
        "X-Tenant-ID and X-User-ID are included in the response for audit correlation",
        "Error responses: 400 for validation errors, 422 for safety filter rejection, 502 for provider errors, 504 for timeouts",
        "app/prompts/system_prompts.py: default system prompts per task_type — LESSON_GENERATION, DIFFERENTIATION, ASSESSMENT_GENERATION, REWRITE; each is a multi-line string with role context and output format instructions",
        "When task_type is provided and no system_prompt is given, the default system prompt for that task_type is used",
        "tests/test_generate.py: test successful generation (mock provider), test validation errors, test safety filter rejection, test provider error handling, test task_type system prompt injection",
        "pytest passes with 0 failures"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Tech Spec 2.10: /v1/generate is the primary gateway endpoint. Safety filters provide a defense-in-depth layer (even though Rails also enforces policies). Task-type-specific system prompts encode domain knowledge about K-12 education content generation."
    },
    {
      "id": "US-085",
      "title": "AI streaming generate endpoint with SSE",
      "description": "As a developer, I need the gateway's /v1/generate_stream endpoint to stream responses via Server-Sent Events so the frontend can show real-time generation progress.",
      "acceptanceCriteria": [
        "POST /v1/generate_stream endpoint accepts same JSON body as /v1/generate",
        "Returns text/event-stream content type (Server-Sent Events)",
        "Each SSE event is: data: { content: str, done: bool }\\n\\n",
        "Final event includes usage stats: data: { content: '', done: true, usage: { prompt_tokens, completion_tokens, total_tokens }, finish_reason: str }\\n\\n",
        "Safety filter check_input runs before streaming begins; check_output runs on the accumulated full response after streaming completes (logged but does not interrupt the stream)",
        "Provider stream method is called with async generator pattern",
        "OpenAI streaming: uses stream=true on Chat Completions API, parses SSE chunks from OpenAI response",
        "Anthropic streaming: uses stream=true on Messages API, parses SSE chunks from Anthropic response",
        "Connection timeout: if no chunks received within 30 seconds, close stream with error event",
        "Client disconnect handling: if client disconnects mid-stream, cancel the provider request gracefully",
        "Error event format: data: { error: str, done: true }\\n\\n",
        "tests/test_generate_stream.py: test streaming returns correct SSE format, test final chunk has usage, test error handling during stream, test input safety filter applied before stream",
        "pytest passes with 0 failures"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Tech Spec 2.10: Streaming provides a better UX for AI generation — teachers see content appear progressively. SSE is simpler than WebSocket for unidirectional streaming. FastAPI's StreamingResponse handles the SSE protocol natively."
    },
    {
      "id": "US-086",
      "title": "AiProviderConfig model with CRUD API",
      "description": "As an admin, I need to register and manage AI providers per tenant so I can control which AI models are available and set API keys securely.",
      "acceptanceCriteria": [
        "AiProviderConfig model: id (bigint PK), tenant_id (FK → tenants, NOT NULL, indexed), provider_name (string, NOT NULL), display_name (string, NOT NULL), status (string, NOT NULL, default 'inactive'), api_key (text, encrypted), default_model (string, NOT NULL), available_models (jsonb, NOT NULL, default []), settings (jsonb, NOT NULL, default {}), created_by_id (FK → users, NOT NULL), timestamps",
        "VALID_PROVIDER_NAMES = %w[openai anthropic].freeze",
        "VALID_STATUSES = %w[inactive active error].freeze",
        "Migration: create_ai_provider_configs with all columns; add_index :ai_provider_configs, [:tenant_id, :provider_name], unique: true",
        "Include TenantScoped concern",
        "encrypts :api_key (Rails encrypted attributes)",
        "belongs_to :created_by, class_name: 'User'",
        "Validates: provider_name presence and inclusion in VALID_PROVIDER_NAMES, status inclusion in VALID_STATUSES, display_name presence, default_model presence, uniqueness of provider_name scoped to tenant_id",
        "activate! method: validates api_key present, sets status to 'active'; deactivate! method: sets status to 'inactive'",
        "Pundit AiProviderConfigPolicy: all CRUD actions require admin role; Scope resolves scope.all for admin, scope.none for others",
        "AiProviderConfigSerializer: attributes :id, :tenant_id, :provider_name, :display_name, :status, :default_model, :available_models, :settings, :created_by_id, :created_at, :updated_at — NOTE: api_key is NEVER serialized",
        "API routes: resources :ai_provider_configs with member routes activate and deactivate",
        "Controller: Api::V1::AiProviderConfigsController with standard CRUD + activate/deactivate; create sets tenant and created_by; api_key accepted in create/update params but never returned in responses",
        "Factory :ai_provider_config with association :tenant, :created_by (factory: :user), provider_name 'openai', display_name 'OpenAI', status 'inactive', default_model 'gpt-4o', available_models ['gpt-4o', 'gpt-4o-mini'], api_key 'sk-test-key-123'",
        "Request specs: list as admin (200), list as teacher (403), create with api_key (verify key not in response), show (no api_key in response), update, delete, activate (with key), activate (without key — 422), deactivate, duplicate provider per tenant (422), Rubocop passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "PRD-14, Tech Spec 2.4: AiProviderConfig is the admin model registry. One config per provider per tenant. API keys are encrypted at rest and never exposed in API responses. Admin-only access ensures institutional control over AI provider configuration."
    },
    {
      "id": "US-087",
      "title": "AiTaskPolicy model with CRUD API",
      "description": "As an admin, I need to define per-tenant policies controlling which AI tasks are available to which roles so I can enforce safe AI usage.",
      "acceptanceCriteria": [
        "AiTaskPolicy model: id (bigint PK), tenant_id (FK → tenants, NOT NULL, indexed), task_type (string, NOT NULL), allowed_roles (jsonb, NOT NULL, default []), ai_provider_config_id (FK → ai_provider_configs, NOT NULL), model_override (string, optional), max_tokens_limit (integer, default 4096), temperature_limit (float, default 1.0), requires_approval (boolean, NOT NULL, default false), enabled (boolean, NOT NULL, default true), settings (jsonb, NOT NULL, default {}), created_by_id (FK → users, NOT NULL), timestamps",
        "VALID_TASK_TYPES = %w[lesson_generation unit_generation differentiation assessment_generation rewrite].freeze",
        "Migration: create_ai_task_policies with all columns; add_index :ai_task_policies, [:tenant_id, :task_type], unique: true",
        "Include TenantScoped concern",
        "belongs_to :ai_provider_config",
        "belongs_to :created_by, class_name: 'User'",
        "Validates: task_type presence and inclusion in VALID_TASK_TYPES, uniqueness of task_type scoped to tenant_id, allowed_roles is an array",
        "allowed_for?(user) method: returns enabled? && allowed_roles includes at least one of the user's role names",
        "effective_model method: returns model_override || ai_provider_config.default_model",
        "Pundit AiTaskPolicyPolicy: admin can CRUD; Scope: admin sees all, teacher/curriculum_lead sees enabled policies where their role is in allowed_roles",
        "AiTaskPolicySerializer: attributes :id, :tenant_id, :task_type, :allowed_roles, :ai_provider_config_id, :model_override, :max_tokens_limit, :temperature_limit, :requires_approval, :enabled, :settings, :created_by_id, :created_at, :updated_at",
        "API routes: resources :ai_task_policies",
        "Controller: Api::V1::AiTaskPoliciesController with standard CRUD; index uses policy_scope",
        "Factory :ai_task_policy with association :tenant, :ai_provider_config, :created_by (factory: :user), task_type 'lesson_generation', allowed_roles ['admin', 'curriculum_lead', 'teacher'], enabled true",
        "Request specs: list as admin (200, all policies), list as teacher (200, only allowed), list as student (200, empty), create, update, delete, allowed_for? checks, Rubocop passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": "PRD-14, PRD-21: Task policies are the admin control plane for AI usage. Each task_type maps to a specific AI workflow (lesson generation, differentiation, etc.). Policies control which roles can use which AI features, with optional model override and token/temperature limits."
    },
    {
      "id": "US-088",
      "title": "AiTemplate model with CRUD API",
      "description": "As an admin, I need to manage prompt templates for AI tasks so I can customize the AI behavior for my school's specific needs and standards.",
      "acceptanceCriteria": [
        "AiTemplate model: id (bigint PK), tenant_id (FK → tenants, NOT NULL, indexed), task_type (string, NOT NULL), name (string, NOT NULL), system_prompt (text, NOT NULL), user_prompt_template (text, NOT NULL), variables (jsonb, NOT NULL, default []), status (string, NOT NULL, default 'draft'), created_by_id (FK → users, NOT NULL), timestamps",
        "VALID_STATUSES = %w[draft active archived].freeze",
        "Migration: create_ai_templates with all columns; add_index :ai_templates, [:tenant_id, :task_type, :status]",
        "Include TenantScoped concern",
        "belongs_to :created_by, class_name: 'User'",
        "Validates: task_type presence and inclusion in AiTaskPolicy::VALID_TASK_TYPES (reuse constant), name presence, system_prompt presence, user_prompt_template presence, status inclusion in VALID_STATUSES",
        "variables is an array of { name: str, description: str, required: bool } objects describing template placeholders",
        "render(variables_hash) method: replaces {{variable_name}} placeholders in user_prompt_template with provided values; raises ArgumentError if required variable is missing",
        "activate! and archive! status transition methods",
        "scope :active — where(status: 'active')",
        "scope :for_task_type — where(task_type: type)",
        "Pundit AiTemplatePolicy: admin can CRUD; curriculum_lead can index/show/create/update (own templates); teacher can index/show active templates; Scope: admin sees all, curriculum_lead sees own + active, teacher sees active only",
        "AiTemplateSerializer: attributes :id, :tenant_id, :task_type, :name, :system_prompt, :user_prompt_template, :variables, :status, :created_by_id, :created_at, :updated_at",
        "API routes: resources :ai_templates with member routes activate and archive",
        "Controller: Api::V1::AiTemplatesController with CRUD + activate/archive; index supports task_type and status filter params",
        "Factory :ai_template with association :tenant, :created_by (factory: :user), task_type 'lesson_generation', name 'Standard Lesson Generator', system_prompt 'You are a K-12 curriculum expert...', user_prompt_template 'Generate a lesson plan for {{subject}} covering {{topic}} for grade {{grade_level}}...', variables [{ name: 'subject', description: 'Subject area', required: true }, { name: 'topic', description: 'Lesson topic', required: true }, { name: 'grade_level', description: 'Grade level', required: true }], status 'draft'",
        "Request specs: list as admin (200), list as teacher (only active), create, update, render template, activate, archive, missing required variable (422), Rubocop passes"
      ],
      "priority": 7,
      "passes": true,
      "notes": "PRD-14, PRD-21: Templates give admins and curriculum leads control over AI prompts. The variable system allows templates to be reused across different contexts (subjects, grades, standards). Mustache-style {{variable}} syntax is simple and familiar."
    },
    {
      "id": "US-089",
      "title": "AiInvocation model for audit logging",
      "description": "As an admin, I need an audit trail of all AI invocations so I can monitor usage, costs, and ensure AI is being used appropriately.",
      "acceptanceCriteria": [
        "AiInvocation model: id (bigint PK), tenant_id (FK → tenants, NOT NULL, indexed), user_id (FK → users, NOT NULL, indexed), ai_provider_config_id (FK → ai_provider_configs, NOT NULL), ai_task_policy_id (FK → ai_task_policies, optional), ai_template_id (FK → ai_templates, optional), task_type (string, NOT NULL), provider_name (string, NOT NULL), model (string, NOT NULL), status (string, NOT NULL, default 'pending'), prompt_tokens (integer), completion_tokens (integer), total_tokens (integer), duration_ms (integer), input_hash (string), error_message (text), context (jsonb, NOT NULL, default {}), started_at (datetime), completed_at (datetime), timestamps",
        "VALID_STATUSES = %w[pending running completed failed].freeze",
        "Migration: create_ai_invocations with all columns; add indexes on tenant_id, user_id, ai_provider_config_id; add_index :ai_invocations, [:tenant_id, :task_type, :created_at]",
        "Include TenantScoped concern",
        "belongs_to :user; belongs_to :ai_provider_config; belongs_to :ai_task_policy, optional: true; belongs_to :ai_template, optional: true",
        "start! sets started_at = Time.current, status = 'running'",
        "complete!(usage) sets completed_at, status = 'completed', token counts from usage hash, duration_ms calculated from started_at",
        "fail!(message) sets completed_at, status = 'failed', error_message",
        "input_hash stores SHA256 of the prompt (for dedup detection without storing full prompts)",
        "context JSONB stores: { linkable_type, linkable_id, subject, grade_level } — metadata for reporting",
        "Do NOT store the full prompt text or generated content in this model (privacy) — only token counts and metadata",
        "Pundit AiInvocationPolicy: index? admin only; show? admin only; Scope: admin sees all",
        "AiInvocationSerializer: all attributes except prompt content",
        "API routes: resources :ai_invocations, only: [:index, :show] (read-only — invocations are created by the system, not the user)",
        "Controller: Api::V1::AiInvocationsController; index supports filters: task_type, user_id, status, date range (start_date/end_date params); ordered by created_at DESC; includes summary endpoint GET /api/v1/ai_invocations/summary returning { total_invocations, total_tokens, by_task_type: { ... }, by_provider: { ... } } for the current tenant",
        "Factory :ai_invocation with associations and sample data",
        "Request specs: list as admin (200 with filters), list as teacher (403), show, summary endpoint, date range filtering, Rubocop passes"
      ],
      "priority": 8,
      "passes": true,
      "notes": "PRD-14, PRD-22: Audit logging is critical for institutional AI governance. Admins need visibility into who is using AI, how much, and for what purpose. Token counts enable cost tracking. Input hashing allows dedup detection without storing sensitive prompt content."
    },
    {
      "id": "US-090",
      "title": "AiGatewayClient service for Rails-to-Gateway communication",
      "description": "As a developer, I need a Rails service that communicates with the FastAPI ai-gateway so Rails controllers and jobs can invoke AI generation.",
      "acceptanceCriteria": [
        "Add faraday gem to apps/core Gemfile (HTTP client for gateway communication)",
        "AiGatewayClient class in app/services/ai_gateway_client.rb: initialize with base_url (from AI_GATEWAY_URL env var, default 'http://localhost:8000')",
        "generate(provider:, model:, prompt:, system_prompt: nil, temperature: 0.7, max_tokens: 2048, task_type: nil, tenant_id:, user_id:) — POST /v1/generate with headers X-Tenant-ID and X-User-ID; returns parsed GenerateResult struct with content, model, provider, usage, finish_reason",
        "generate_stream(provider:, model:, prompt:, system_prompt: nil, temperature: 0.7, max_tokens: 2048, task_type: nil, tenant_id:, user_id:, &block) — POST /v1/generate_stream; parses SSE chunks and yields each to the block; returns final accumulated content and usage",
        "health — GET /v1/health; returns parsed response; used for connectivity checks",
        "providers — GET /v1/providers; returns list of available providers and models",
        "Error handling: AiGatewayError < StandardError with status_code, response_body; raised on non-2xx responses; timeout errors (Faraday::TimeoutError) wrapped with descriptive message",
        "Connection timeout: 10 seconds; read timeout: 120 seconds for generate, 180 seconds for stream",
        "AiGatewayError class defined in app/errors/ai_gateway_error.rb",
        "Service specs: test generate with WebMock stubbed gateway (mock HTTP response), test generate_stream with SSE parsing, test error handling (502 from gateway), test timeout handling, test health check",
        "Request spec: add GET /api/v1/ai/health endpoint on AiController that proxies to gateway health (admin only); returns gateway status or 503 if gateway unreachable",
        "Routes: namespace :ai do; get :health; end",
        "AiPolicy: health? requires admin role",
        "Rubocop passes"
      ],
      "priority": 9,
      "passes": true,
      "notes": "Tech Spec 2.1: Rails Core communicates with AI Gateway via HTTP. Faraday provides a clean HTTP client with middleware support. The client encapsulates all gateway communication, connection management, and error handling so controllers/jobs don't deal with HTTP details directly."
    },
    {
      "id": "US-091",
      "title": "AI unit plan generation endpoint and Sidekiq job",
      "description": "As a teacher, I need to generate a unit plan draft using AI so I can quickly scaffold a new unit aligned to standards.",
      "acceptanceCriteria": [
        "POST /api/v1/ai/generate_unit endpoint accepts: { subject: str, topic: str, grade_level: str, num_lessons: int (default 5), standards: [str] (optional standard codes), additional_context: str (optional) }",
        "Controller: Api::V1::AiGenerationsController#generate_unit",
        "Before generating: looks up AiTaskPolicy for task_type 'unit_generation'; verifies policy.allowed_for?(Current.user); returns 403 if not allowed or policy not found/disabled",
        "Looks up active AiTemplate for task_type 'unit_generation' (falls back to nil if none); if template exists, renders it with provided variables; if no template, constructs prompt from default system prompt + user input",
        "Creates AiInvocation record (status: pending) for audit",
        "Enqueues AiUnitGenerationJob with invocation_id",
        "Returns 202 with { invocation_id, status: 'pending' }",
        "GET /api/v1/ai/invocations/:id/result endpoint returns the generation result: { status, content (parsed JSON), error_message }; content is stored in a temporary cache (Rails.cache) keyed by invocation_id with 1-hour TTL",
        "AiUnitGenerationJob in app/jobs/ai_unit_generation_job.rb: loads invocation, calls AiGatewayClient.generate with the constructed prompt, parses the AI response as JSON (expects { title, description, essential_questions: [], enduring_understandings: [], lessons: [{ title, objectives, activities, duration_minutes }] }), stores result in Rails.cache, updates invocation with token counts and status",
        "Job handles malformed AI output gracefully — if JSON parsing fails, stores raw text content and logs warning",
        "Pundit AiGenerationPolicy: generate_unit? delegates to AiTaskPolicy.allowed_for? check",
        "Job spec: stub AiGatewayClient, verify invocation lifecycle (pending → running → completed), verify result stored in cache, verify token counts recorded",
        "Request specs: generate unit as teacher (202), generate as student (403), get result (200 with content), get result before complete (200 with pending status), no task policy configured (403), Rubocop passes"
      ],
      "priority": 10,
      "passes": true,
      "notes": "PRD-21: 'Invoke AI → review output → save draft → enforce policy'. This is the core AI-assisted planning workflow. The async job pattern prevents request timeouts. Results are cached temporarily (not persisted) — teachers must explicitly save to create a unit plan draft."
    },
    {
      "id": "US-092",
      "title": "AI lesson plan generation endpoint and Sidekiq job",
      "description": "As a teacher, I need to generate a lesson plan draft using AI so I can quickly create detailed lesson content aligned to unit objectives.",
      "acceptanceCriteria": [
        "POST /api/v1/ai/generate_lesson endpoint accepts: { unit_plan_id: int (optional, for context), subject: str, topic: str, grade_level: str, objectives: str (optional), duration_minutes: int (default 45), standards: [str] (optional), additional_context: str (optional) }",
        "Controller: Api::V1::AiGenerationsController#generate_lesson",
        "When unit_plan_id is provided, loads the unit plan's current version and includes title, essential questions, and existing lesson titles in the prompt context (so AI avoids duplication)",
        "Same policy/template/invocation pattern as US-091 but with task_type 'lesson_generation'",
        "Enqueues AiLessonGenerationJob with invocation_id",
        "Returns 202 with { invocation_id, status: 'pending' }",
        "AiLessonGenerationJob in app/jobs/ai_lesson_generation_job.rb: constructs prompt with lesson context, calls AiGatewayClient.generate, parses response as JSON (expects { title, objectives, activities, materials, duration_minutes }), stores result in Rails.cache, updates invocation",
        "Result endpoint reused from US-091: GET /api/v1/ai/invocations/:id/result",
        "Job spec: stub AiGatewayClient, verify correct prompt includes unit context when unit_plan_id provided, verify invocation lifecycle",
        "Request specs: generate lesson (202), generate with unit context (202, verify unit data included), Rubocop passes"
      ],
      "priority": 11,
      "passes": true,
      "notes": "PRD-21: Lesson generation is the most frequent AI task. Providing unit plan context prevents duplication and ensures coherence across lessons. The same async pattern as unit generation ensures consistency."
    },
    {
      "id": "US-093",
      "title": "AI differentiation and assessment generation endpoints",
      "description": "As a teacher, I need AI to suggest differentiation modifications and generate assessment questions so I can support diverse learners and create aligned assessments.",
      "acceptanceCriteria": [
        "POST /api/v1/ai/differentiate endpoint accepts: { content: str (existing lesson/unit text to differentiate), differentiation_type: str (e.g. 'ell', 'gifted', 'iep', 'struggling'), grade_level: str, subject: str, additional_context: str (optional) }",
        "Uses task_type 'differentiation'; same policy/template/invocation/job pattern",
        "AiDifferentiationJob: constructs prompt asking AI to modify the provided content for the specified learner profile; response JSON: { modifications: [{ section, original, suggested, rationale }] }",
        "POST /api/v1/ai/generate_assessment endpoint accepts: { topic: str, grade_level: str, question_types: [str] (e.g. ['multiple_choice', 'short_answer', 'true_false']), num_questions: int (default 5), difficulty: str ('easy', 'medium', 'hard'), standards: [str] (optional), additional_context: str (optional) }",
        "Uses task_type 'assessment_generation'; same pattern",
        "AiAssessmentGenerationJob: constructs prompt for question generation; response JSON: { questions: [{ question_text, question_type, choices (for MC): [{ text, correct: bool }], correct_answer (for non-MC), explanation, difficulty, standard_code (optional) }] }",
        "POST /api/v1/ai/rewrite endpoint accepts: { content: str, instruction: str (e.g. 'simplify language', 'add more detail', 'make more engaging'), grade_level: str, additional_context: str (optional) }",
        "Uses task_type 'rewrite'; same pattern",
        "AiRewriteJob: constructs prompt for rewriting; response JSON: { rewritten_content: str, changes_summary: str }",
        "Job specs for all three: stub AiGatewayClient, verify prompt construction, verify invocation lifecycle",
        "Request specs: differentiate (202), generate assessment (202), rewrite (202), policy enforcement for each, Rubocop passes"
      ],
      "priority": 12,
      "passes": true,
      "notes": "PRD-5, PRD-21, UX 3.7: These are the 'Differentiate', 'Assess', and 'Rewrite' capabilities from the AI Assistant Panel. Each follows the same async job pattern but with different prompt construction and response parsing."
    },
    {
      "id": "US-094",
      "title": "Next.js Admin AI Registry and AI Policies pages",
      "description": "As an admin, I need web interfaces to manage AI provider configurations and task policies so I can control AI availability and behavior for my school.",
      "acceptanceCriteria": [
        "AI Registry page at /admin/ai-registry: 'use client', ProtectedRoute + AppShell wrapper, admin only",
        "Lists AI provider configs: provider name, display name, status badge (active/inactive/error), default model, available models count",
        "Add Provider form: provider_name (dropdown: OpenAI, Anthropic), display_name, api_key (password input), default_model (dropdown populated from available models for selected provider), available_models (checkbox list)",
        "Edit inline: display_name, default_model, available_models, api_key (shows 'Change API Key' button, not the current key)",
        "Activate/Deactivate toggle button per provider",
        "Delete button with confirmation dialog",
        "AI Policies page at /admin/ai-policies: 'use client', ProtectedRoute + AppShell wrapper, admin only",
        "Lists task policies: task_type (badge), allowed_roles (tags), provider config name, model override, max tokens, requires approval, enabled toggle",
        "Add Policy form: task_type (dropdown from valid types), allowed_roles (multi-checkbox: admin, curriculum_lead, teacher), ai_provider_config_id (dropdown of active providers), model_override (optional), max_tokens_limit, temperature_limit, requires_approval (checkbox), enabled (checkbox)",
        "Edit inline for each policy field",
        "Delete button with confirmation",
        "Update AppShell NAV_ITEMS: add AI Registry and AI Policies to Admin children: [{ label: 'Curriculum Map', href: '/admin/curriculum-map' }, { label: 'Approvals', href: '/admin/approvals' }, { label: 'Integrations', href: '/admin/integrations' }, { label: 'AI Registry', href: '/admin/ai-registry' }, { label: 'AI Policies', href: '/admin/ai-policies' }]",
        "npm run lint passes",
        "npm run build succeeds"
      ],
      "priority": 13,
      "passes": true,
      "notes": "PRD-14, UX 3.6: The AI Registry and AI Policies pages are the admin control center for AI features. They map directly to the AiProviderConfig and AiTaskPolicy models. API keys are never displayed — only a 'Change' flow."
    },
    {
      "id": "US-095",
      "title": "Next.js AI Assistant Panel component",
      "description": "As a teacher, I need an AI assistant panel that provides Draft, Differentiate, Assess, and Rewrite capabilities so I can use AI directly within my planning workflow.",
      "acceptanceCriteria": [
        "AiAssistantPanel component at src/components/AiAssistantPanel.tsx: 'use client', sliding panel from right side",
        "Panel is toggled by an 'AI Assistant' button (fixed position, bottom-right) — only visible when user has at least one allowed AI task policy",
        "On mount: fetches GET /api/v1/ai_task_policies to determine which AI capabilities are available for the current user",
        "Tab-based interface with tabs for each enabled task_type: Draft, Differentiate, Assess, Rewrite",
        "Draft tab: subject, topic, grade_level inputs; 'Generate' button calls POST /api/v1/ai/generate_lesson (or generate_unit depending on context); shows loading spinner while pending; polls GET /api/v1/ai/invocations/:id/result every 2 seconds until completed/failed",
        "Differentiate tab: paste or auto-fill content from current plan; differentiation_type dropdown (ELL, Gifted, IEP, Struggling); 'Suggest Modifications' button; shows modifications as a list of original → suggested with rationale",
        "Assess tab: topic, grade_level, question types (checkboxes), num questions, difficulty; 'Generate Questions' button; shows generated questions in a list",
        "Rewrite tab: content textarea (auto-filled from current context), instruction input; 'Rewrite' button; shows rewritten content with changes summary",
        "All tabs show 'Apply to Plan' button when results are available — this copies the AI output to the clipboard and shows a toast notification (actual apply-to-form integration is in US-096)",
        "Policy banner: shows message like 'AI features are governed by your school's AI policy' at the top of the panel",
        "Error states: policy not configured (show message), generation failed (show error), gateway unreachable (show retry option)",
        "AiAssistantPanel accepts optional context prop: { type: 'unit'|'lesson'|'assignment', id: number, subject: string, gradeLevel: string } for pre-filling fields",
        "npm run lint passes",
        "npm run build succeeds"
      ],
      "priority": 14,
      "passes": true,
      "notes": "UX 3.7: The AI Assistant Panel is the primary AI interaction surface. It provides Draft, Differentiate, Assess, and Rewrite capabilities in a contextual panel. The panel respects task policies — only showing capabilities the user is allowed to use."
    },
    {
      "id": "US-096",
      "title": "Next.js AI generation integration in planners and editors",
      "description": "As a teacher, I need AI generation integrated into the Unit Planner, Lesson Editor, and Quiz Builder so I can apply AI-generated content directly to my plans.",
      "acceptanceCriteria": [
        "Unit Planner (/plan/units/[id]): add AiAssistantPanel with context type 'unit', passing unit's subject/grade from course; 'Apply to Plan' in Draft tab populates form fields (title, description, essential_questions, enduring_understandings) — does NOT auto-save, user must review and click save",
        "Unit Planner: 'Generate Lessons' button in lessons section calls POST /api/v1/ai/generate_unit with current unit context; on completion, shows generated lessons in a preview modal; user selects which lessons to add; selected lessons are created via existing POST /api/v1/unit_plans/:id/lesson_plans endpoint",
        "Lesson Editor (/plan/units/[id]/lessons/[lessonId]): add AiAssistantPanel with context type 'lesson'; 'Apply to Plan' populates form fields (title, objectives, activities, materials, duration); Differentiate tab auto-fills with current lesson content",
        "Quiz Builder: 'AI Generate Questions' button in the questions panel; calls POST /api/v1/ai/generate_assessment with quiz's topic/settings; shows generated questions in a preview; user selects which to add; selected questions are created via POST /api/v1/question_banks/:id/questions (into the quiz's linked bank or a new bank)",
        "Admin AI Invocations page at /admin/ai-usage: shows invocation history table with user, task_type, provider, model, tokens, status, duration, created_at; summary stats at top (total invocations, total tokens, by task type chart); date range filter",
        "All AI buttons hidden when no task policies are configured or user has no allowed policies",
        "Loading states: show skeleton/spinner during AI generation with cancel button",
        "Success toast after applying AI content: 'AI content applied — review and save when ready'",
        "npm run lint passes",
        "npm run build succeeds"
      ],
      "priority": 15,
      "passes": true,
      "notes": "PRD-21: 'Invoke AI → review output → save draft → enforce policy'. This story completes the AI workflow loop by connecting generation results to existing editor forms. The preview-then-apply pattern ensures teachers maintain control over AI-generated content."
    }
  ]
}
